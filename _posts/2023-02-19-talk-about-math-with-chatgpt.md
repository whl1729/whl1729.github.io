# 和 ChatGPT 聊聊数学

昨天（2023年2月18日）折腾一个工作中的问题，想起 ChatGPT 来，于是按照[网上教程][1] 火速注册了一个账号。
遗憾的是，它没能帮我解决我的问题。但在好奇心驱动下，我和 ChatGPT 聊了一下数学。

## 判断一个数是否为质数

之前已经看到过 ChatGPT 在判断一个数是否为质数时会出错，于是我先测试这个问题。

今年是 2023 年，因为 `2023 = 7 * 17 * 17`，所以 2023 是合数，而非质数。

很遗憾，ChatGPT 果然误认为 2023 是质数。
在我反复问它「你确定吗」的时候，它显然没抓住重点，一直在强调「2022是偶数」和「2023不是偶数」。

因此我尝试引导它做出正确的解答：

首先我让它验证能否被较小的质数整除，结果它很快回复「已经检查过了」，并一口咬定「找不到任何因子」，很像一位粗心而鲁莽的学生。

我决定提示得再明显些，于是直接让它验证能否被7整除。这时它终于回答2023可以被7整除，所以不是一个质数。

然而我发现了一个更大的 bug：它说完「2023可以被7整除，商为289」，紧跟着却说「余数为6」！
在我再次追问后，它依然没能纠正自己的错误——它没能理解「整除」的概念，而且在处理多位数除以一位数的除法运算上也会出错。

  ![chatgpt_2023_1](/assets/images/chatgpt_2023_1.jpg)
  ![chatgpt_2023_2](/assets/images/chatgpt_2023_2.jpg)

## 鸡兔同笼

小学数学的一个经典问题是「鸡兔同笼」问题，让我们来问问 ChatGPT 吧。

首先我问了一个有解的「鸡兔同笼」问题，ChatGPT 用二元一次方程组迅速解决了。
然后我修改题目条件，使问题变为无解，ChatGPT 也能识别出来。Well Done。

  ![chatgpt_chick_rabbit](/assets/images/chatgpt_chick_rabbit.jpg)

## x/sin(x)

让我们将问题调至高中以上的难度吧。我随便想到一条题目：求 `x / sin(x)` 的最大值。

显然这个函数是发散的，最大值不存在。然而 ChatGPT 没能识别出来，直接求出一个零点后代进去就当做最大值。
这种做法有点像死记硬背的学生试图通过套公式来获得分数。

  ![chatgpt_x_sinx](/assets/images/chatgpt_x_sinx.jpg)

## 费马大定理

费马大定理的内容小学生就能理解：当整数 n > 2 时，关于 x, y, z 的方程 x^n + y^n = z^n 没有正整数解。
这本来是17世纪法国数学家费马提出来的一个猜想，1995年被英国数学家安德鲁·怀尔斯证明后，就成了定理。

我首先按照费马大定理的一般表述方式来问 ChatGPT，它正确回答没有正整数解。这在意料之中，一般搜索引擎都能做到这事。

然后我问它 n = 3 的情况，这个时候它开始犯错了，至少有两个错误：

- 搞错「水仙花数」的定义：水仙花数是一个 3 位数，它的每个位上的数字的 3 次幂之和等于它本身。
- 把 3 次方当做平方。

在我指出它的错误后，它继续列举了更多错误的例子。看来是死性不改啊。

  ![chatgpt_fermat_1](/assets/images/chatgpt_fermat_1.jpg)
  ![chatgpt_fermat_2](/assets/images/chatgpt_fermat_2.jpg)

## 总结

基于以上测试，可以得出以下结论：

- ChatGPT 对话能力确实很不错，基本没有语法错误，也有一定的联系上下文的能力。之前清华计算机教授甚至说 ChatGPT 对话能力已经超过 80% 甚至 90% 的人。
- ChatGPT 能解决一些数学问题，但在数学运算和逻辑推理上有时也会犯错误，甚至在简单的除法运算上也可能犯错误。
- ChatGPT 在常识性问题上有时会犯错误，比如搞错「水仙花数」的定义等。

个人认为 ChatGPT 十分适合作为工具助手，协助我们解决工作或学习上的一些问题，但要辨证看待其答案——可以参考但不宜照搬。
考虑到它还会不断迭代优化，其潜力确实惊人。

  [1]: https://www.woshipm.com/pd/5749183.html
